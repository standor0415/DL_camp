{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbU-HSp7lIKZ"
      },
      "source": [
        "## <span style=\"color:#FFC1C1; font-weight:bold\">2. nn.Module</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcjjuNHJlIKd"
      },
      "source": [
        "####  신경망 구성\n",
        "\n",
        "- 레이어(layer): 신경망의 핵심 데이터 구조로 하나 이상의 텐서를 입력받아 하나 이상의 텐서를 출력\n",
        "- 모듈(module): 한 개 이상의 계층이 모여서 구성\n",
        "- 모델(model): 한 개 이상의 모듈이 모여서 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6hmgLsylIKg"
      },
      "source": [
        "#### `torch.nn` 패키지\n",
        "\n",
        "주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때 사용합니다! (`weight`값들을 직접 선언 안함)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1hNCXrNlIKi"
      },
      "source": [
        "1. `nn.Linear` 계층 예제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tHPokdNWlIKj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6531, 0.4664, 0.1383,  ..., 0.6163, 0.0599, 0.7942],\n",
            "        [0.8310, 0.7567, 0.2412,  ..., 0.7044, 0.4166, 0.4248],\n",
            "        [0.8487, 0.6084, 0.6123,  ..., 0.3053, 0.3782, 0.7291],\n",
            "        ...,\n",
            "        [0.3679, 0.3665, 0.5465,  ..., 0.3084, 0.2305, 0.5257],\n",
            "        [0.0633, 0.5598, 0.1698,  ..., 0.6993, 0.8576, 0.4154],\n",
            "        [0.4716, 0.8281, 0.2044,  ..., 0.5622, 0.0158, 0.0064]])\n"
          ]
        }
      ],
      "source": [
        "input = torch.rand(128, 20)\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=20, out_features=30, bias=True)\n"
          ]
        }
      ],
      "source": [
        "m = nn.Linear(20, 30)\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([150, 20])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(150, 30)\n",
        "layer = nn.Linear(30, 20)\n",
        "output = layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx4sd8jGlIKm",
        "outputId": "a6bc4bd3-d6b2-40f0-8c07-ada2bffb770b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 3.0967,  0.8809, -0.8750,  ..., -0.8847, -0.4556,  0.5978],\n",
            "        [ 0.4595, -0.6009, -0.2070,  ...,  0.1534, -1.6834, -0.4870],\n",
            "        [-0.1542, -0.0213, -0.0940,  ..., -2.0807,  1.4820,  0.5268],\n",
            "        ...,\n",
            "        [-1.4588, -0.1802, -0.3278,  ..., -0.2211, -0.2941,  0.3257],\n",
            "        [-0.6010,  0.4895, -0.3033,  ...,  1.7948, -1.1842,  0.0715],\n",
            "        [-0.1302, -1.1537,  1.2227,  ...,  0.8190, -0.5941,  2.0321]])\n",
            "Linear(in_features=20, out_features=30, bias=True)\n",
            "tensor([[ 0.7558, -0.8719, -1.5267,  ...,  0.3118,  0.8699, -0.5677],\n",
            "        [ 0.2956,  0.0601, -0.0753,  ...,  0.1426,  0.5856,  2.2660],\n",
            "        [-0.7623, -0.3979, -0.3701,  ..., -0.8264,  0.2385, -0.2082],\n",
            "        ...,\n",
            "        [ 0.3585,  0.8921,  0.0272,  ..., -1.2086, -0.5353, -0.5779],\n",
            "        [ 0.3434,  0.2216, -0.1482,  ..., -0.4836, -0.0712, -0.3755],\n",
            "        [ 0.0490,  0.3846, -0.4800,  ..., -0.8756, -1.0684, -0.5390]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "torch.Size([128, 30])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(128, 20)\n",
        "print(input)\n",
        "\n",
        "m = nn.Linear(20, 30)\n",
        "print(m)\n",
        "\n",
        "output = m(input)\n",
        "print(output)\n",
        "print(output.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCGGtRVFlIKo"
      },
      "source": [
        "2. `nn.Conv2d` 계층 예제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVDZ1G4flIKq",
        "outputId": "f007d2c3-5cae-41cb-9495-1af62d6b2935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 16, 50, 100])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(20, 16, 50, 100)\n",
        "print(input.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q7cE9g_olIKt"
      },
      "outputs": [],
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4,2))\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4,2), dilation=(3,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4NJZ2bQlIKu",
        "outputId": "6e666ae6-5336-42ff-bba5-e6ee2a79bd50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 33, 26, 100])\n"
          ]
        }
      ],
      "source": [
        "output = m(input)\n",
        "print(output.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nkcoH9xlIKw"
      },
      "source": [
        "#### `nn.Module` 상속 클래스 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzPOm2jklIKx"
      },
      "source": [
        "nn.Module은 <span style=\"color:#FFC1C1; font-weight:bold\">PyTorch의 모든 Neural Network의 Base Class</span>입니다.\n",
        "\n",
        "이 클래스를 상속하여 사용자 정의 신경망 모델을 만들 수 있죠!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kXpPHf3SlIKy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX-yIXEflIKz"
      },
      "source": [
        "### 기본 method  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4NOMOgGlIKz"
      },
      "source": [
        "간단하게 nn.Module을 상속한 Add 클래스를 만들어보겠습니다!\n",
        "\n",
        "클래스 내에서 2가지를 반드시 정의해줘야합니다\n",
        "- `__init__()`: 모델에서 사용될 모듈과 활성화 함수 등을 정의\n",
        "- `forward()`: 모델에서 실행되어야 하는 연산을 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Add_on(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 반드시 Add_on class의 부모 클라스인 nn.Module을 super()을 사용해서 초기화해야한다.\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        output = torch.add(x, y)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ftFv6jBplIK0"
      },
      "outputs": [],
      "source": [
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 반드시 Add class의 부모 클래스인 nn.Module을 super()을 사용해서 초기화 시켜줘야 한다.\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = torch.add(x1, x2)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5544, 0.3971],\n",
            "        [0.1577, 0.7266],\n",
            "        [0.8806, 0.5282],\n",
            "        [0.0155, 0.1727],\n",
            "        [0.7245, 0.4197]])\n",
            "tensor([[0.1618, 0.9445],\n",
            "        [0.1408, 0.7338],\n",
            "        [0.8525, 0.1282],\n",
            "        [0.7855, 0.6631],\n",
            "        [0.1461, 0.3881]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(5, 2)\n",
        "x2 = torch.rand(5, 2)\n",
        "print(x1)\n",
        "print(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7161, 1.3416],\n",
            "        [0.2985, 1.4604],\n",
            "        [1.7331, 0.6564],\n",
            "        [0.8010, 0.8358],\n",
            "        [0.8706, 0.8078]])\n"
          ]
        }
      ],
      "source": [
        "model = Add()\n",
        "out = model(x1, x2)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lt4rt02PlIK0"
      },
      "outputs": [],
      "source": [
        "x1 = torch.tensor([1])\n",
        "x2 = torch.tensor([2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hIvgoMHRlIK1"
      },
      "outputs": [],
      "source": [
        "model = Add()\n",
        "output = model(x1, x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZPMJNnlIK2",
        "outputId": "cd626fd6-1e16-499e-f518-ee31a686a5f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3])\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hlno3zslIK2"
      },
      "source": [
        "엇... 그런데 우리가 흔히 알고 있는 클래스에서 함수 사용법이랑 다른거 눈치챘나요?\n",
        "\n",
        "model.forward()와 같이 호출하지 않았는데 단순히 model 객체를 데이터와 함께 호출하면 자동으로 forward() 함수가 실행되었잖아요.\n",
        "\n",
        "왜 이런 일이 발생하는지 이해하기 위해서 `nn.Module`의 소스코드를 뜯어봐야합니다!\n",
        "\n",
        "https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/module.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htndNvzlIK3"
      },
      "source": [
        "그리고 이를 이해하기 전에 `__call__`이란 무엇을 의미하는지 짚고 넘어갈게요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idJMwd2jlIK3"
      },
      "source": [
        "- `__call__` : 클래스의 인스턴스를 마치 함수처럼 호출할 수 있게 해주는 메소드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kvu-6az4lIK4"
      },
      "outputs": [],
      "source": [
        "class Plus:\n",
        "\n",
        "\tdef add(self, n1, n2):\n",
        "\t\treturn n1 + n2\n",
        "\n",
        "\t__call__ = add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84PeVo66lIK4",
        "outputId": "17c990af-bafe-4991-ab4d-80bb5cec605f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "myinstance = Plus()\n",
        "myinstance(1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyu1ormelIK5"
      },
      "source": [
        "즉, `__call__`가 `add` 메소드를 가리키고 있어서, Plus의 인스턴스를 함수처럼 호출했을때 add 메소드가 실행되는거에요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i9NEcBylIK5"
      },
      "source": [
        "그렇다면 `nn.Module`의 소스코드 상 `__call__`은 무엇을 어떤 메소드를 가리키고 있을까요? (1634번째 줄)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaGB2KA7lIK6"
      },
      "source": [
        "![__call__메소드](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/__call__.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sLBeuQHlIK6"
      },
      "source": [
        "`_wrapped_call_impl`을 가리키고 있군요. (1507번째 줄)\n",
        "\n",
        "`_wrapped_call_impl`은 무엇을 가리킬까요?\n",
        "\n",
        "![_wrapped_call_impl](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/_wrapped_call_impl.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "073o9eDzlIK7"
      },
      "source": [
        "`_call_impl`을 가리키고 있군요. (1513번째 줄)\n",
        "\n",
        "`_call_impl`은 복잡한 error handling 코드를 가지고 있지만, 문제가 없다면 `forward`을 하는 것을 볼 수 있습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoKiefTPlIK7"
      },
      "source": [
        "![_call_impl](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/_call_impl.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsr9tbIAlIK8"
      },
      "source": [
        "즉, 우리가 오버라이딩한 forward() 메소드는 클래스를 인스턴스 한 후, input만 넣어주면 실행되는 것이죠!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sea1hYnlIK9"
      },
      "source": [
        "여기까지 왔다면, 다된것과 다름 없습니다.\n",
        "\n",
        "이제 추가적으로 많이 쓰이는 함수들을 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j31ps1RrlIK-"
      },
      "source": [
        "### 추가적 method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXcZmFa2lILA"
      },
      "source": [
        "1. `apply`\n",
        "\n",
        "- 모든 submodule에 함수를 적용하는 역할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVSbPNi1lILA"
      },
      "source": [
        "잠깐! submodule을 짚고 넘어갈게요.  \n",
        "\n",
        "우선, 모듈은 다른 모듈을 포함할 수 있고, 트리 구조로 형성됩니다. 예를 들어, nn.Sequential 안에는 nn.Linear, nn.Conv2d 포함될 수 있겠죠.\n",
        "\n",
        "이때, 모델 내의 모든 nn.Module을 상속 받는 클래스는 submodule입니다.\n",
        "\n",
        "apply는 모든 submodule에 재귀적(recursive)으로 연산을 수행하는 함수입니다. 파라미터를 설정할 때 모델에 사용하면, 모든 트리구조의 submodule들에 일괄 적용할 수 있겠죠~?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hmFqzb9zlILB"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def init_weights(m):\n",
        "     print(m)\n",
        "     if type(m) == nn.Linear:   # 모델의 모든 submodule에 대해 nn.Linear가 있으면 아래를 수행\n",
        "         m.weight.fill_(1.0)    # fill_(1.0)은 fill의 in-place operation으로, nn.Linear의 weight를 모두 1.0으로 채운다는 뜻\n",
        "         print(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQSPcO9dlILB",
        "outputId": "9733a719-bc8c-4fbf-f7e6-f5aeea3b3609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=2, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "Linear(in_features=2, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
        "net.apply(init_weights)                    # apply(fn) 적용 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGGzBoo3lILC"
      },
      "source": [
        "2. `cpu`, `cuda`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S0ghvmGlILC"
      },
      "source": [
        "- 모델을 어느 디바이스에 올릴 것인지 결정\n",
        "- 기본적으로 모델은 CPU에 올라가 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uBsVP97Uo5pA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAnl7uqJlWzj",
        "outputId": "bc8029d1-0044-49b1-f22b-7ab38d470076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()  # True인 경우 GPU, 즉 cuda를 사용할 수 있다는 뜻(cuda는 gpu로 학습하기 위해 사용하는 프로그램)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWUFVYienT9M",
        "outputId": "38a88e72-b128-4f75-b8e7-45e0ace854bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhFwZcR2rQCj"
      },
      "source": [
        "데이터가 클수록, 많을수록 cuda를 사용하면 시간을 많이 아낄 수 있습니다.😎\n",
        "\n",
        "model을 cuda에 올리는 방법으로는 아래와 같이 '**to(device)**'를 붙이면 됩니다. cuda를 사용할 수 있는 상황에서는 cuda에서 모델을 불러오고, 그렇지 않으면 cpu를 활용합니다.\n",
        "\n",
        "이때, 위와 같이 device를 꼭 먼저 정의해주어야합니다.\n",
        "\n",
        "[예시] clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").**to(device)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRIqdBvmlILO"
      },
      "source": [
        "3. `parameters`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s_NKkjclILO"
      },
      "source": [
        "- 모델의 모든 파라미터를 담은 iterator를 return\n",
        "- 보통 optimizer 선언할 시 argument로 넣어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amQIeqqBlILP"
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhYWxBoAlILP"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrrRky6dlILQ"
      },
      "source": [
        "4. `state_dict`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_V-IIHElILR"
      },
      "source": [
        "- 모델의 submodule을 dictionary 형태로 반환\n",
        "- 모델 저장/로드할 때 씀\n",
        "\n",
        "아래는 파이토치 공식 문서에 나와있는 예시 코드입니다.\n",
        "\n",
        "모델의 구조를 세세히 이해하려고 하기보단 우선 state_dict에 어떤 값들이 저장되는지 살펴봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge5ASMbltNm2",
        "outputId": "0830bd13-d193-41a7-ad4e-5324bd6e2afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
            "conv1.bias \t torch.Size([6])\n",
            "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
            "conv2.bias \t torch.Size([16])\n",
            "fc1.weight \t torch.Size([120, 400])\n",
            "fc1.bias \t torch.Size([120])\n",
            "fc2.weight \t torch.Size([84, 120])\n",
            "fc2.bias \t torch.Size([84])\n",
            "fc3.weight \t torch.Size([10, 84])\n",
            "fc3.bias \t torch.Size([10])\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "# 모델 정의\n",
        "class TheModelClass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TheModelClass, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "model = TheModelClass()\n",
        "\n",
        "# 옵티마이저 초기화\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 모델의 state_dict 출력\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# 옵티마이저의 state_dict 출력\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uXjdk3jLuCe9"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'full_model.pt')            # 1번\n",
        "torch.save(model.state_dict(), 'model.pt')    # 2번"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_YBYLJNumzA"
      },
      "source": [
        "**[모델 전체를 저장하는 1번 코드]**\n",
        "\n",
        "\n",
        "*   파라미터, 에포크 등 모든 정보 저장\n",
        "*   나중에 학습을 이어서 하고 싶을 때\n",
        "*   더 큰 용량 필요\n",
        "\n",
        "**[모델의 state_dict만 저장하는 2번 코드]**\n",
        "\n",
        "\n",
        "*   가중치, 편향 등 학습되는 변수에 대한 정보 저장\n",
        "*   코드 상 모델이 구현되어 있을 때만!\n",
        "*   작은 용량 사용\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2r0HMgqlILR"
      },
      "source": [
        "5. `train`, `eval`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXOQ43rFlILR"
      },
      "source": [
        "- 모델 train을 시작할 때는 `model.train()`, evaluation을 시작 할 때는 `model.eval()`을 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDdZEYlHlILS"
      },
      "source": [
        "🙋‍♀️ <span style=\"color:#D8BFD8; font-weight:bold\"> 이렇게 train과 evaluation 시작할때 `train()`, `eval()` 메소드를 호출하는 이유가 무엇일까요? </span> 🙋‍♀️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVdNmSyDlILS"
      },
      "source": [
        "1. Dropout이나 BatchNorm 같은 레이어들은 학습 시와 평가 시에 다르게 동작하도록 설계되어 있는데요, `train()`, `eval()` 메소드를 통해 모델 내 해당 레이어들을 일일이 모드 변경하지 않고 손쉽게 일괄 변경 시켜줍니다.\n",
        "\n",
        "2. 단순한 모델은 output만으로 loss를 구할 수 있었습니다. (output과 target을 통해 loss를 구한 후, `backward()`, `optimizer.step()`을 해주면 되죠) 하지만 보다 복잡한 모델들은 output만으로 loss를 구할 수 없습니다. 예를 들어, Object detection model인 detectron2만 봐도 forward() 내부에 loss를 구하는 과정이 포함되어 있으며, 심지어 loss도 detector_losses, proposal_losses로 2개입니다. 모델을 사용하는 사람 입장에서는 사용자가 loss를 계산하기 너무 어렵죠. 그래서 `forward()` 내부에 Loss를 구하는 과정을 추상화하고, train mode이면 loss나 loss의 총합을 return하고 inference mode(train mode = False)이면 prediction을 return하는 경우가 많습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC8BaTE1lILT"
      },
      "source": [
        "참고를 위해 detectron2 `forward()` 내부에 구현된 loss 를 첨부합니다~\n",
        "\n",
        "![detectron2_forward()](https://github.com/jkyoon2/ds_codingCamp/blob/main/04_pytorch/image/detectron2_forward().png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5NYh8xUlILT"
      },
      "source": [
        "그럼 이제 모든 준비를 마친 셈입니다.\n",
        "\n",
        "이제 직접... 사과 토마토 복숭아 분류 모델을 만들어봅시다 🍎🍅🍑"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ybenv",
      "language": "python",
      "name": "ybenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
